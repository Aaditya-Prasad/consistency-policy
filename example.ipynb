{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/juno/u/aadityap/miniforge3/envs/robodiff-retry/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from diffusion_policy.dataset.base_dataset import BaseImageDataset, LinearNormalizer\n",
    "from consistency_policy.utils import get_policy, rmat_to_quat, rot6d_to_rmat\n",
    "from consistency_policy.policy_wrapper import PolicyWrapper\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = '/juno/u/aadityap/Consistency-Accelerated-Policy-Networks/outputs/ctm/jimmy/checkpoints/epoch=0200-val_mse_error=0.228.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using the CTM base workspace! Ensure that you don't wish to use the normal DP base workspace.\n",
      "Using scheduler singular\n",
      "Using CTM scheduler\n",
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['arm_quat', 'arm_pos', 'base_pose', 'gripper_pos']\n",
      "using obs modality: rgb with keys: ['base_image', 'wrist_image']\n",
      "using obs modality: depth with keys: []\n",
      "using obs modality: scan with keys: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/juno/u/aadityap/miniforge3/envs/robodiff-retry/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/juno/u/aadityap/miniforge3/envs/robodiff-retry/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference mode or invalid teacher time embed! You should be doing inference only!\n",
      "Using losses:  {'ctm': 1, 'dsm': 1}\n",
      "CM params: 2.594075e+08\n",
      "Teacher params: 2.557375e+08\n",
      "Vision params: 2.239418e+07\n",
      "YOU ARE EXCLUDING:  ['optimizer']\n",
      "model\n",
      "dict_keys(['model', 'optimizer'])\n",
      "optimizer\n",
      "dict_keys(['model', 'optimizer'])\n",
      "_output_dir\n",
      "global_step\n",
      "epoch\n",
      "dict_keys(['params_dict.action.offset', 'params_dict.action.scale', 'params_dict.action.input_stats.max', 'params_dict.action.input_stats.mean', 'params_dict.action.input_stats.min', 'params_dict.action.input_stats.std', 'params_dict.base_pose.offset', 'params_dict.base_pose.scale', 'params_dict.base_pose.input_stats.max', 'params_dict.base_pose.input_stats.mean', 'params_dict.base_pose.input_stats.min', 'params_dict.base_pose.input_stats.std', 'params_dict.arm_pos.offset', 'params_dict.arm_pos.scale', 'params_dict.arm_pos.input_stats.max', 'params_dict.arm_pos.input_stats.mean', 'params_dict.arm_pos.input_stats.min', 'params_dict.arm_pos.input_stats.std', 'params_dict.arm_quat.offset', 'params_dict.arm_quat.scale', 'params_dict.arm_quat.input_stats.max', 'params_dict.arm_quat.input_stats.mean', 'params_dict.arm_quat.input_stats.min', 'params_dict.arm_quat.input_stats.std', 'params_dict.gripper_pos.offset', 'params_dict.gripper_pos.scale', 'params_dict.gripper_pos.input_stats.max', 'params_dict.gripper_pos.input_stats.mean', 'params_dict.gripper_pos.input_stats.min', 'params_dict.gripper_pos.input_stats.std', 'params_dict.base_image.offset', 'params_dict.base_image.scale', 'params_dict.base_image.input_stats.max', 'params_dict.base_image.input_stats.mean', 'params_dict.base_image.input_stats.min', 'params_dict.base_image.input_stats.std', 'params_dict.wrist_image.offset', 'params_dict.wrist_image.scale', 'params_dict.wrist_image.input_stats.max', 'params_dict.wrist_image.input_stats.mean', 'params_dict.wrist_image.input_stats.min', 'params_dict.wrist_image.input_stats.std'])\n"
     ]
    }
   ],
   "source": [
    "policy = get_policy(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "policy = policy.to(device)\n",
    "policy.eval()\n",
    "for param in policy.parameters():\n",
    "    param.requires_grad = False\n",
    "pw = PolicyWrapper(policy, n_obs=2, n_acts=8, d_pos=6, d_rot=6, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = {\n",
    "    'base_pose': np.zeros(3),\n",
    "    'arm_pos': np.zeros(3),\n",
    "    'arm_quat': np.zeros(4),\n",
    "    'gripper_pos': np.zeros(1),\n",
    "    'base_image': np.zeros((84, 84, 3), dtype=np.uint8),\n",
    "    'wrist_image': np.zeros((84, 84, 3), dtype=np.uint8),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.15361279  0.00192948  0.00346004  1.         -0.13698481 -0.02300356\n",
      "  0.09278427  0.915581   -0.3452509   0.04831392  1.          1.\n",
      "  0.46922943  0.46922943]\n"
     ]
    }
   ],
   "source": [
    "action = pw.get_action(obs)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generalize this to any environment\n",
    "base_pose = action[:3]\n",
    "arm_pos = action[3:6]\n",
    "arm_6d = torch.from_numpy(action[6:12])\n",
    "arm_quat = rmat_to_quat(rot6d_to_rmat(arm_6d))\n",
    "gripper_pos = action[12:13]\n",
    "\n",
    "action_dict = {\n",
    "    'base_pose': base_pose,\n",
    "    'arm_pos': arm_pos,\n",
    "    'arm_quat': arm_quat,\n",
    "    'gripper_pos': gripper_pos\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
